{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining laboratory - Introduction\n",
    "\n",
    "Welcome to the data mining class. During our meetings, we will be dealing with processing and exploring data with the use of the Python language in the Jupyter Notebook setting. We are also going to use low-code and no-code solutions to the presented problems. Today, we are going to set up our working stations and get familiar with the setup.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Course assignements\n",
    "\n",
    "This course consists of X notebooks, X homeworks and 3 assignments. In order to get a pass mark, you need to complete all homeworks. You can get a maximum of 4 points for each assignment. Once the assignment is announced you have two weeks to complete it. Each week of delay deducts 1 point from the mark you get. The amount of points you gather during the course will indicate your final grade.\n",
    "\n",
    "| Points| Grade |\n",
    "| --- | --- |\n",
    "| 0| 2.0  |\n",
    "| 6 | 3.0 |\n",
    "| 7.5 | 3.5 |\n",
    "| 9 | 4.0 |\n",
    "| 10.5 | 4.5 |\n",
    "| 11.5 | 5.0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What is the Jupyter Notebook?\n",
    "\n",
    "It's a computing platform that is very commonly used for code presentation, on-hand code execution, as well as preparing code snippets, which later on might be used in a larger library. In this setting you can easily combine Markdown text and executable Python code. This format is very popular in machine learning, data mining and artificial intelligence field in general. A single file in this setting is very often referred to as just a *Notebook*. The file you are viewing right now is a Notebook. Notebook files are usually named with the extension *.ipynb*, which stems from the original open-source project name *IPython Notebook*. The Notebook uses an interactive kernel,  which allows us to maintain the current execution of the code. During the execution, all variables, defined functions, and classes, etc. are stored in the memory, which gives us flexible access to everything we coded (this is nothing new compared to a standard Python interpreter). The Notebooks are delivered to us in several different settings, here are some:\n",
    "  \n",
    "  - **Advanced, modern IDE, which supports Jupyter Notebooks.** In this setting, the IDE is responsible for setting up the interactive kernel with the use of the Python interpreter. A good example of an IDE, which supports the Jupyter Notebooks is Visual Studio Code. Prior to using this option, we need to set up the Python interpreter on the machine.\n",
    "  \n",
    "      **Pros**:\n",
    "\n",
    "         * full customization\n",
    "         * full access to data on hand\n",
    "         * usually supports version control\n",
    "         * easy setup process\n",
    "      **Cons**:\n",
    "      \n",
    "         * you need to set up an IDE on every machine you work on\n",
    "         * requires installation of Python interpreter on the machine\n",
    "\n",
    "\n",
    "  - **A stand-alone Jupyter Notebook server.** This is the original method of delivering the Notebooks. In order to use this setting, one must download and run the Jupyter Server as a separate process on a machine on hand. The Jupyter Notebook server often comes in bundle with complete Python distributions (e.g. WinPython), in that case, the server executable file is usually within the Python folder. The Jupyter Notebook server allows us to access, view and run the notebooks via the web application accessible through a browser. The server allows us to set up the connection details (e.g. the IP address, port, authentication method, password). If you want to use the server in a public network. you need to be very careful while using this option, as it allows an easy access to the Remote Code Execution, which is a substantial vulnerability. Whoever has the access to the *Notebooks* via the server, essentially has the same privileges, as the user, who started the server. Nothing stops us from using the server on the *localhost*. Running the server in a default setting is as simple as running the command:\n",
    "\n",
    "                 jupyter notebook\n",
    "  \n",
    "      Once the server is running, you have access to files and directories, starting with the directory on which, the server was started. Opening the notebook file, switches the application view, so that you can execute the code and read the markdown.\n",
    "      \n",
    "      **Pros**:\n",
    "\n",
    "         * full customization\n",
    "         * access to data on the server machine\n",
    "         * ability to use it in a network setting with many users and a single server\n",
    "      **Cons**:\n",
    "      \n",
    "         * fairly hard setup process (if you want to use it with several users in a network setting)\n",
    "         * if you do not have a server machine, you can only run it in an offline setting\n",
    "         * no native support for version control\n",
    "         * requires installation of Python interpreter on the machine\n",
    "          \n",
    "\n",
    "  - **External Notebook server paired up with virtual machine.** In this setting, we are using a virtual machine with a temporary python environment as the working space. Although we are not forced to maintain the Notebook server, this option comes with several limitations. We are forced to follow the rules of the virtual machine provider. Usually we not permitted to use such a notebook in order to host data, download torrents, use it as an SSH server, connect to the remote proxy, etc. (nothing really related to Data Mining). Such a notebook does not have direct access to our files, we usually need to upload the data on the virtual machine (or a cloud drive) in order to process the data. Other than that, we can consume the Nootebook files as normal. A good example of this setting is Google Colaboratory.\n",
    "\n",
    "      **Pros**:\n",
    "\n",
    "         * access to notebooks on any machine with no setup\n",
    "         * limited customization\n",
    "         * ability to modify and create new Notebooks on hand on any machine\n",
    "         * no need to install any software on the machine (except for a browser)\n",
    "      **Cons**:\n",
    "      \n",
    "         * no support for version control\n",
    "         * restrictions of use\n",
    "         * requires an account (e.g. Google Account)\n",
    "         * limited access to data on hand\n",
    "         * requires uploading the data to an external server (usually limitted space)\n",
    "         * limited customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course I propose one of the two options - those options are not obligatory, you can use any setup you want:\n",
    " - Visual Studio Code\n",
    " - Google Colaboratory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Visual Studio Code.\n",
    "\n",
    "In the class we will be using the Google Colaboratory service. However, if you want to make your setup at home, or with a personal laptop, you can use the Visual Studio Code setup. Process of setting it up comprised of 2 (pretty obvious) steps:\n",
    " - installing Python interpreter - \n",
    "    - if you are using a Linux machine, it is very likely you already have the Python interpreter installed. If this is not the case, use your default package manager to install python (i.e. `apt install python3` on Debianoids).\n",
    "    - if you are using a Windows machine I suggest using a [WinPython](https://winpython.github.io/) package. It comes with a pre-installed set of libraries.\n",
    "    - you can also use the [default Python installer](https://www.python.org/downloads/).\n",
    " - installing Visual Studio Code - VSC is an multi-platform IDE. You can find it [here](https://code.visualstudio.com/).\n",
    " \n",
    "Once you have everything installed you need to create a space on the computer for this class (we are going to use toy data sets, so you do not need gigabytes of free space). You start by creating a dedicated directory on your hard drive. Download this notebook (.ipynb version, not the html) and paste it into the newly created directory. Then, you open the Visual Studio Code application and from the File menu you choose the Open Directory option. In the file explorer you should be able to see this notebook. Upon the first execution of the code block you will need to choose a Python interpreter, which you have already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Google Colaboratory\n",
    "\n",
    "Using Google Colab is much easier. You just need to download this notebook, log in to your Google account on the [Colaboratory website](https://colab.research.google.com/). From the File menu use the \"Send notebook\" option. Choose the downloaded file. That's it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have everything set up, switch from the HTML version of the notebook to the interactive one (either in Colab or in VSC). Starting the next week you will be downloading and opening the notebook at the beginning of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is a Notebook organized?\n",
    "\n",
    "Each Notebook consists of list of cells. There are two types of cells:\n",
    "\n",
    " - **Code cell** - the code cell is filled with the code in the programming language the Notebook is set up for (usually it's Python). You can execute the code and immediately see the result. Everything that *happened* in the execution is available in the next cell you run. Once the code cell is executed, it is annotated with a number, which refers to the order of execution. The first cell you run will be annotated with number [1], second with number [2], etc. The enumeration helps us to keep up with the current status of execution.\n",
    " - **Markdown cell** - the markdown cell allows us to insert a formatted text into the notebook. The text is formatted with use of the [Markdown](https://www.markdownguide.org/) language. The Markdown is a lightweight markup language, which is used to add simple formatting to plaintext documents. It was created in 2004 by John Gruber. It is one of the most popular markup languages. This is the same language you can use for example in the Discord app.\n",
    " \n",
    "\n",
    " Each of the code cells can be executed at any point. In most of the IDEs we are allowed to run all cells at once, restart the interpreter and clear all variables and definitions, add a new cell, and reorder existing the cells. \n",
    "\n",
    "\n",
    " #### Exercise 1. \n",
    " \n",
    " Execute the cells in the following order:\n",
    "   1. Run cell 2\n",
    "   2. Run cell 1\n",
    "   3. Run cell 3\n",
    "   3. Run cell 2\n",
    "   4. Run cell 3\n",
    "   5. Restart the kernel\n",
    "   6. Run cell 1\n",
    "   7. Run cell 2\n",
    "   8. Run cell 3.\n",
    "   9. Run cell 3.\n",
    "\n",
    "Observe the results and make notes. Can we execute the cell 2 immediately, why? How does the annotation change when we run a single cell multiple times? What is the value of the _ expression? You can restart this exercise by restarting the kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a + 2\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a + _\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.\n",
    "\n",
    "Create a new markdown cell directly below this one and use the Markdown language to answer the questions asked in Exercise 1. Use the following features:\n",
    "  - Level 4 heading\n",
    "  - Bullet list\n",
    "  - Bold text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <B>Answer to exc1\n",
    "  - we cannot execute cell 2 immidiately, as the a variable isnt yet in the memory\n",
    "  - _ represents the result of the last expression evaluated by the interpreter.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell magic\n",
    "\n",
    "In order to use a package in your Python script you need to import it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens when the package is not installed on the machine? Well. Probably you need open the terminal, type an apropriate command and download the package. This even is more complicated when you have no direct access to the machine. In this case we can use something called [cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html). Ususally the *Code cell* is interpreted as a python script. However, we can add a special decorator to change its behaviour. When we add `%%bash` at the beginning of the cell it is going to be executed as if it was a bash terminal. So, in order to install the numpy package (it should be already installed), you can create a cell similar to this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%%bash` is not the only magical command out there. Sometimes we will compare time of executions of different code variants. In this case we can use the `%%time` or `%%timeit` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = np.zeros((10000,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.2 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = [[0 for _ in range(10000)] for _ in range(10000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.46 µs ± 204 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = np.zeros((1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.2 ms ± 416 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = [[0 for _ in range(1000)] for _ in range(1000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full list of cell magics can be found [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy data sets\n",
    "\n",
    "During the course we will be using different data sets in order to get familiar with data mining techiques. This section illustrates several techniques of loading up the data sets.\n",
    "\n",
    "#### Scikit-learn package\n",
    "\n",
    "Among various packages we are going to use the scikit-learn package (sklearn). Today we will get familiar with the toy data sets, which the package provides. The package provides 7 different data sets (including boston data set, which is deprecated), among them:\n",
    "\n",
    "- Iris data set - The famous Iris database, first used by Sir R.A. Fisher.\n",
    "- Digits data set - The data set contains images of hand-written digits: 10 classes where each class refers to a digit.\n",
    "- Wine data set - The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators.\n",
    "\n",
    "#### Loading the data set\n",
    "\n",
    "The datasets are loaded into a dictionary-like structure, [sklearn.utils.Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html). We use a set of dedicated *load* functions to load the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits, load_diabetes, load_linnerud, load_wine\n",
    "\n",
    "iris_data_set = load_iris()\n",
    "breast_cancer_data_set = load_breast_cancer()\n",
    "digits_data_set = load_digits()\n",
    "diabetes_data_set = load_diabetes()\n",
    "linnerud_data_set = load_linnerud()\n",
    "wine_data_set = load_wine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain a description of each of the data sets by using the DESCR field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 150 (50 in each of three classes)\n",
      ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - sepal length in cm\n",
      "    - sepal width in cm\n",
      "    - petal length in cm\n",
      "    - petal width in cm\n",
      "    - class:\n",
      "            - Iris-Setosa\n",
      "            - Iris-Versicolour\n",
      "            - Iris-Virginica\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============== ==== ==== ======= ===== ====================\n",
      "                Min  Max   Mean    SD   Class Correlation\n",
      "============== ==== ==== ======= ===== ====================\n",
      "sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "============== ==== ==== ======= ===== ====================\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: 33.3% for each of 3 classes.\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "  Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "  Structure and Classification Rule for Recognition in Partially Exposed\n",
      "  Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "  Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "  on Information Theory, May 1972, 431-433.\n",
      "- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "  conceptual clustering system finds 3 classes in the data.\n",
      "- Many, many more ...\n",
      "\n",
      "|details-end|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris_data_set.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data set consists of a list of entries. Each entry is comprised of a set of features. Each feature has a name, which corresponds to its real source. We can obtain the names of features by using the feature_names field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data_set.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in each of the data sets is organized as a numpy array (more on that next week). We can get to it by using the data field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function Bunch.__sizeof__>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(iris_data_set.data))\n",
    "iris_data_set.data[:5]\n",
    "iris_data_set.__sizeof__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry corresponds to a certain class, we can obtain names of the classes with use of the target_names field, and the list of classes corresponding to each entry with the target field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris_data_set.target_names)\n",
    "print(iris_data_set.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 1.\n",
    "\n",
    "Write a function, which processes a sci-kit learn Bunch object. The function is expected to prepare a the data set description. The description has the following format:\n",
    "\n",
    "  `Dataset data_set_name.`\n",
    "\n",
    "  `Number of samples: NNN`\n",
    "\n",
    "  `Number of classes: NNN`\n",
    "\n",
    "  `  Number of samples in class target_name1: NNN`\n",
    "\n",
    "  `  Number of samples in class target_name2: NNN`\n",
    "\n",
    "  `  ...`\n",
    "\n",
    "  `Number of features: NNN`\n",
    "\n",
    "  `  Average value of feature feature_name1: NNN`\n",
    "\n",
    "  `  Standard deviation of feature feature_name1: NNN`\n",
    "\n",
    "  `  Average value of feature feature_name2: NNN`\n",
    "\n",
    "  `  Standard deviation of feature feature_name2: NNN`\n",
    "\n",
    "  `  Average value of feature feature_name3: NNN`\n",
    "\n",
    "  `  Standard deviation of feature feature_name3: NNN`\n",
    "  \n",
    "  `  ...`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990749\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06833155\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286131\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04688253\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452873\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00422151\n",
      "   0.00306441]]\n",
      "Dataset Iris\n",
      "Number of samples 150\n",
      "Number of classes 3\n",
      "\tNumber of samples in class setosa: 50\n",
      "\tNumber of samples in class versicolor: 50\n",
      "\tNumber of samples in class virginica: 50\n",
      "Number of features 4\n",
      "\tAverage value of feature sepal length (cm): 2.55\n",
      "\tStandard deviation of feature sepal length (cm): 1.8874586088176872\n",
      "\tAverage value of feature sepal width (cm): 2.375\n",
      "\tStandard deviation of feature sepal width (cm): 1.7640507362318127\n",
      "\tAverage value of feature petal length (cm): 2.35\n",
      "\tStandard deviation of feature petal length (cm): 1.7298843892006195\n",
      "\tAverage value of feature petal width (cm): 2.3499999999999996\n",
      "\tStandard deviation of feature petal width (cm): 1.6560495161679194\n",
      "Dataset BC\n",
      "Number of samples 569\n",
      "Number of classes 2\n",
      "\tNumber of samples in class malignant: 212\n",
      "\tNumber of samples in class benign: 357\n",
      "Number of features 30\n",
      "\tAverage value of feature mean radius: 118.87261573333332\n",
      "\tStandard deviation of feature mean radius: 397.01313120979364\n",
      "\tAverage value of feature mean texture: 124.6974489\n",
      "\tStandard deviation of feature mean texture: 415.05100808685097\n",
      "\tAverage value of feature mean perimeter: 112.91308503333333\n",
      "\tStandard deviation of feature mean perimeter: 366.8095088755571\n",
      "\tAverage value of feature mean area: 41.33339493333333\n",
      "\tStandard deviation of feature mean area: 120.84759716160407\n",
      "\tAverage value of feature mean smoothness: 111.22280716666664\n",
      "\tStandard deviation of feature mean smoothness: 357.9333654058023\n",
      "\tAverage value of feature mean compactness: 50.18484339999999\n",
      "\tStandard deviation of feature mean compactness: 155.0805918701768\n",
      "\tAverage value of feature mean concavity: 102.2645787666667\n",
      "\tStandard deviation of feature mean concavity: 336.1451845392585\n",
      "\tAverage value of feature mean concave points: 60.4812649\n",
      "\tStandard deviation of feature mean concave points: 187.39668928686058\n",
      "\tAverage value of feature mean symmetry: 52.16324133333332\n",
      "\tStandard deviation of feature mean symmetry: 158.79650075527996\n",
      "\tAverage value of feature mean fractal dimension: 49.78114663333334\n",
      "\tStandard deviation of feature mean fractal dimension: 150.33417158106133\n",
      "\tAverage value of feature radius error: 77.08483170000001\n",
      "\tStandard deviation of feature radius error: 245.66631692607567\n",
      "\tAverage value of feature texture error: 82.10649849999999\n",
      "\tStandard deviation of feature texture error: 266.4057760818828\n",
      "\tAverage value of feature perimeter error: 98.9490263\n",
      "\tStandard deviation of feature perimeter error: 305.4027877919586\n",
      "\tAverage value of feature area error: 66.7292417\n",
      "\tStandard deviation of feature area error: 206.0588172218999\n",
      "\tAverage value of feature smoothness error: 52.929048400000006\n",
      "\tStandard deviation of feature smoothness error: 159.17458781169992\n",
      "\tAverage value of feature compactness error: 65.3176521\n",
      "\tStandard deviation of feature compactness error: 202.00107032316456\n",
      "\tAverage value of feature concavity error: 72.58193943333335\n",
      "\tStandard deviation of feature concavity error: 233.36343227978804\n",
      "\tAverage value of feature concave points error: 83.67936593333333\n",
      "\tStandard deviation of feature concave points error: 270.3522354542835\n",
      "\tAverage value of feature symmetry error: 139.9113830333333\n",
      "\tStandard deviation of feature symmetry error: 476.7177991516655\n",
      "\tAverage value of feature fractal dimension error: 51.842925400000006\n",
      "\tStandard deviation of feature fractal dimension error: 159.6881222607319\n",
      "\tAverage value of feature worst radius: 47.15662006666667\n",
      "\tStandard deviation of feature worst radius: 143.64883622907044\n",
      "\tAverage value of feature worst texture: 26.07457946666666\n",
      "\tStandard deviation of feature worst texture: 73.60159387847419\n",
      "\tAverage value of feature worst perimeter: 67.74664676666664\n",
      "\tStandard deviation of feature worst perimeter: 212.129812392845\n",
      "\tAverage value of feature worst area: 151.84085016666663\n",
      "\tStandard deviation of feature worst area: 522.2990976231556\n",
      "\tAverage value of feature worst smoothness: 120.49778663333335\n",
      "\tStandard deviation of feature worst smoothness: 422.1118655433552\n",
      "\tAverage value of feature worst compactness: 94.76384543333332\n",
      "\tStandard deviation of feature worst compactness: 302.69896893992905\n",
      "\tAverage value of feature worst concavity: 62.5317651\n",
      "\tStandard deviation of feature worst concavity: 194.07040943541267\n",
      "\tAverage value of feature worst concave points: 98.3413449\n",
      "\tStandard deviation of feature worst concave points: 312.0007682087885\n",
      "\tAverage value of feature worst symmetry: 80.070207\n",
      "\tStandard deviation of feature worst symmetry: 257.66566620955814\n",
      "\tAverage value of feature worst fractal dimension: 85.77393963333333\n",
      "\tStandard deviation of feature worst fractal dimension: 272.8568518623647\n",
      "Dataset Digits\n",
      "Number of samples 1797\n",
      "Number of classes 10\n",
      "\tNumber of samples in class 0: 178\n",
      "\tNumber of samples in class 1: 182\n",
      "\tNumber of samples in class 2: 177\n",
      "\tNumber of samples in class 3: 183\n",
      "\tNumber of samples in class 4: 181\n",
      "\tNumber of samples in class 5: 182\n",
      "\tNumber of samples in class 6: 181\n",
      "\tNumber of samples in class 7: 179\n",
      "\tNumber of samples in class 8: 174\n",
      "\tNumber of samples in class 9: 180\n",
      "Number of features 64\n",
      "\tAverage value of feature pixel_0_0: 4.59375\n",
      "\tStandard deviation of feature pixel_0_0: 5.183262576553497\n",
      "\tAverage value of feature pixel_0_1: 4.890625\n",
      "\tStandard deviation of feature pixel_0_1: 6.468957575171984\n",
      "\tAverage value of feature pixel_0_2: 5.375\n",
      "\tStandard deviation of feature pixel_0_2: 6.298561343672061\n",
      "\tAverage value of feature pixel_0_3: 4.171875\n",
      "\tStandard deviation of feature pixel_0_3: 5.360604815165449\n",
      "\tAverage value of feature pixel_0_4: 4.03125\n",
      "\tStandard deviation of feature pixel_0_4: 5.637399527929523\n",
      "\tAverage value of feature pixel_0_5: 5.34375\n",
      "\tStandard deviation of feature pixel_0_5: 6.406097559161896\n",
      "\tAverage value of feature pixel_0_6: 4.78125\n",
      "\tStandard deviation of feature pixel_0_6: 6.157994676637842\n",
      "\tAverage value of feature pixel_0_7: 4.53125\n",
      "\tStandard deviation of feature pixel_0_7: 5.681573148125438\n",
      "\tAverage value of feature pixel_1_0: 5.578125\n",
      "\tStandard deviation of feature pixel_1_0: 6.219436990948216\n",
      "\tAverage value of feature pixel_1_1: 5.140625\n",
      "\tStandard deviation of feature pixel_1_1: 6.272128794067848\n",
      "\tAverage value of feature pixel_1_2: 5.03125\n",
      "\tStandard deviation of feature pixel_1_2: 5.5900825966616985\n",
      "\tAverage value of feature pixel_1_3: 4.984375\n",
      "\tStandard deviation of feature pixel_1_3: 6.5633741977259685\n",
      "\tAverage value of feature pixel_1_4: 4.0\n",
      "\tStandard deviation of feature pixel_1_4: 5.570569988789298\n",
      "\tAverage value of feature pixel_1_5: 5.015625\n",
      "\tStandard deviation of feature pixel_1_5: 5.759481822123845\n",
      "\tAverage value of feature pixel_1_6: 5.4375\n",
      "\tStandard deviation of feature pixel_1_6: 6.348904925260734\n",
      "\tAverage value of feature pixel_1_7: 5.15625\n",
      "\tStandard deviation of feature pixel_1_7: 6.28544635944815\n",
      "\tAverage value of feature pixel_2_0: 4.921875\n",
      "\tStandard deviation of feature pixel_2_0: 6.230732018340622\n",
      "\tAverage value of feature pixel_2_1: 5.15625\n",
      "\tStandard deviation of feature pixel_2_1: 6.036914438477656\n",
      "\tAverage value of feature pixel_2_2: 4.09375\n",
      "\tStandard deviation of feature pixel_2_2: 5.387249849180934\n",
      "\tAverage value of feature pixel_2_3: 4.140625\n",
      "\tStandard deviation of feature pixel_2_3: 5.628796461889078\n",
      "\tAverage value of feature pixel_2_4: 5.265625\n",
      "\tStandard deviation of feature pixel_2_4: 6.144718737206366\n",
      "\tAverage value of feature pixel_2_5: 5.28125\n",
      "\tStandard deviation of feature pixel_2_5: 6.560937313943794\n",
      "\tAverage value of feature pixel_2_6: 4.15625\n",
      "\tStandard deviation of feature pixel_2_6: 5.624218695738992\n",
      "\tAverage value of feature pixel_2_7: 4.46875\n",
      "\tStandard deviation of feature pixel_2_7: 5.637399527929523\n",
      "\tAverage value of feature pixel_3_0: 4.046875\n",
      "\tStandard deviation of feature pixel_3_0: 5.699313795043663\n",
      "\tAverage value of feature pixel_3_1: 4.015625\n",
      "\tStandard deviation of feature pixel_3_1: 5.599922397620792\n",
      "\tAverage value of feature pixel_3_2: 5.90625\n",
      "\tStandard deviation of feature pixel_3_2: 6.700556763247365\n",
      "\tAverage value of feature pixel_3_3: 5.078125\n",
      "\tStandard deviation of feature pixel_3_3: 6.155040331661118\n",
      "\tAverage value of feature pixel_3_4: 4.875\n",
      "\tStandard deviation of feature pixel_3_4: 5.938486760109852\n",
      "\tAverage value of feature pixel_3_5: 5.03125\n",
      "\tStandard deviation of feature pixel_3_5: 6.1210925035895345\n",
      "\tAverage value of feature pixel_3_6: 5.375\n",
      "\tStandard deviation of feature pixel_3_6: 6.125\n",
      "\tAverage value of feature pixel_3_7: 4.25\n",
      "\tStandard deviation of feature pixel_3_7: 5.833630944789017\n",
      "\tAverage value of feature pixel_4_0: 5.609375\n",
      "\tStandard deviation of feature pixel_4_0: 6.296370947567734\n",
      "\tAverage value of feature pixel_4_1: 5.625\n",
      "\tStandard deviation of feature pixel_4_1: 6.137741848595459\n",
      "\tAverage value of feature pixel_4_2: 4.578125\n",
      "\tStandard deviation of feature pixel_4_2: 5.936657012526073\n",
      "\tAverage value of feature pixel_4_3: 4.921875\n",
      "\tStandard deviation of feature pixel_4_3: 6.104057788420339\n",
      "\tAverage value of feature pixel_4_4: 5.421875\n",
      "\tStandard deviation of feature pixel_4_4: 6.11812033915442\n",
      "\tAverage value of feature pixel_4_5: 5.0\n",
      "\tStandard deviation of feature pixel_4_5: 6.031169040907409\n",
      "\tAverage value of feature pixel_4_6: 4.65625\n",
      "\tStandard deviation of feature pixel_4_6: 5.429142283777429\n",
      "\tAverage value of feature pixel_4_7: 5.0\n",
      "\tStandard deviation of feature pixel_4_7: 5.656854249492381\n",
      "\tAverage value of feature pixel_5_0: 5.28125\n",
      "\tStandard deviation of feature pixel_5_0: 5.985578371176841\n",
      "\tAverage value of feature pixel_5_1: 5.3125\n",
      "\tStandard deviation of feature pixel_5_1: 6.336587705539946\n",
      "\tAverage value of feature pixel_5_2: 4.1875\n",
      "\tStandard deviation of feature pixel_5_2: 5.894581728163585\n",
      "\tAverage value of feature pixel_5_3: 4.03125\n",
      "\tStandard deviation of feature pixel_5_3: 5.553627052431591\n",
      "\tAverage value of feature pixel_5_4: 5.484375\n",
      "\tStandard deviation of feature pixel_5_4: 6.3368766643651036\n",
      "\tAverage value of feature pixel_5_5: 4.390625\n",
      "\tStandard deviation of feature pixel_5_5: 5.721716273057849\n",
      "\tAverage value of feature pixel_5_6: 4.953125\n",
      "\tStandard deviation of feature pixel_5_6: 6.17056948217707\n",
      "\tAverage value of feature pixel_5_7: 4.15625\n",
      "\tStandard deviation of feature pixel_5_7: 5.815439444917297\n",
      "\tAverage value of feature pixel_6_0: 4.859375\n",
      "\tStandard deviation of feature pixel_6_0: 5.609331476154266\n",
      "\tAverage value of feature pixel_6_1: 4.796875\n",
      "\tStandard deviation of feature pixel_6_1: 5.57107397495088\n",
      "\tAverage value of feature pixel_6_2: 4.125\n",
      "\tStandard deviation of feature pixel_6_2: 5.429951657243368\n",
      "\tAverage value of feature pixel_6_3: 4.546875\n",
      "\tStandard deviation of feature pixel_6_3: 5.774214469031697\n",
      "\tAverage value of feature pixel_6_4: 5.53125\n",
      "\tStandard deviation of feature pixel_6_4: 6.169402194499885\n",
      "\tAverage value of feature pixel_6_5: 4.53125\n",
      "\tStandard deviation of feature pixel_6_5: 5.758061604177225\n",
      "\tAverage value of feature pixel_6_6: 4.359375\n",
      "\tStandard deviation of feature pixel_6_6: 5.602363305728663\n",
      "\tAverage value of feature pixel_6_7: 5.9375\n",
      "\tStandard deviation of feature pixel_6_7: 6.343980907127637\n",
      "\tAverage value of feature pixel_7_0: 4.640625\n",
      "\tStandard deviation of feature pixel_7_0: 6.2459166348403174\n",
      "\tAverage value of feature pixel_7_1: 4.3125\n",
      "\tStandard deviation of feature pixel_7_1: 5.803756865169319\n",
      "\tAverage value of feature pixel_7_2: 5.203125\n",
      "\tStandard deviation of feature pixel_7_2: 6.1977306519705255\n",
      "\tAverage value of feature pixel_7_3: 4.28125\n",
      "\tStandard deviation of feature pixel_7_3: 5.721310902013628\n",
      "\tAverage value of feature pixel_7_4: 4.3125\n",
      "\tStandard deviation of feature pixel_7_4: 5.7578071997940325\n",
      "\tAverage value of feature pixel_7_5: 5.5625\n",
      "\tStandard deviation of feature pixel_7_5: 6.480439317669752\n",
      "\tAverage value of feature pixel_7_6: 5.09375\n",
      "\tStandard deviation of feature pixel_7_6: 6.34852037387453\n",
      "\tAverage value of feature pixel_7_7: 5.109375\n",
      "\tStandard deviation of feature pixel_7_7: 6.1950514210436545\n",
      "Dataset Diabetes\n",
      "Number of samples 442\n",
      "Number of classes 0\n",
      "Number of features 10\n",
      "\tAverage value of feature age: 0.004954860930426746\n",
      "\tStandard deviation of feature age: 0.03718039277164492\n",
      "\tAverage value of feature sex: -0.027755472179700556\n",
      "\tStandard deviation of feature sex: 0.042827190942887144\n",
      "\tAverage value of feature bmi: 0.0036948674945973168\n",
      "\tStandard deviation of feature bmi: 0.040864028986017764\n",
      "\tAverage value of feature bp: -0.013317738684371338\n",
      "\tStandard deviation of feature bp: 0.03671634106446056\n",
      "\tAverage value of feature s1: -0.010731858314485337\n",
      "\tStandard deviation of feature s1: 0.024905197117111765\n",
      "\tAverage value of feature s2: -0.05183933786588736\n",
      "\tStandard deviation of feature s2: 0.03912867110431815\n",
      "\tAverage value of feature s3: -0.026283791302877058\n",
      "\tStandard deviation of feature s3: 0.030693555934114054\n",
      "\tAverage value of feature s4: 0.038627300562837065\n",
      "\tStandard deviation of feature s4: 0.04280941471794163\n",
      "\tAverage value of feature s5: 0.007135736120193671\n",
      "\tStandard deviation of feature s5: 0.032600430343913335\n",
      "\tAverage value of feature s6: -0.013012904160805083\n",
      "\tStandard deviation of feature s6: 0.038348793861057676\n",
      "Dataset Linnerud\n",
      "Number of samples 20\n",
      "Number of classes 3\n",
      "\tNumber of samples in class Weight: 1\n",
      "\tNumber of samples in class Waist: 1\n",
      "\tNumber of samples in class Pulse: 4\n",
      "Number of features 3\n",
      "\tAverage value of feature Chins: 75.66666666666667\n",
      "\tStandard deviation of feature Chins: 65.04528337157807\n",
      "\tAverage value of feature Situps: 57.333333333333336\n",
      "\tStandard deviation of feature Situps: 44.13111776916097\n",
      "\tAverage value of feature Jumps: 71.33333333333333\n",
      "\tStandard deviation of feature Jumps: 41.95500235040182\n",
      "Dataset Wine\n",
      "Number of samples 178\n",
      "Number of classes 3\n",
      "\tNumber of samples in class class_0: 59\n",
      "\tNumber of samples in class class_1: 71\n",
      "\tNumber of samples in class class_2: 48\n",
      "Number of features 13\n",
      "\tAverage value of feature alcohol: 95.76923076923077\n",
      "\tStandard deviation of feature alcohol: 281.7045333313049\n",
      "\tAverage value of feature malic_acid: 91.85384615384615\n",
      "\tStandard deviation of feature malic_acid: 277.78975770392816\n",
      "\tAverage value of feature ash: 103.21692307692307\n",
      "\tStandard deviation of feature ash: 313.3600789797974\n",
      "\tAverage value of feature alcalinity_of_ash: 126.96076923076923\n",
      "\tStandard deviation of feature alcalinity_of_ash: 391.6656348795004\n",
      "\tAverage value of feature magnesium: 69.89923076923077\n",
      "\tStandard deviation of feature magnesium: 194.40449110282083\n",
      "\tAverage value of feature total_phenols: 124.24846153846154\n",
      "\tStandard deviation of feature total_phenols: 383.7945069724794\n",
      "\tAverage value of feature flavanoids: 110.49692307692308\n",
      "\tStandard deviation of feature flavanoids: 341.3862409327957\n",
      "\tAverage value of feature nonflavanoid_phenols: 112.98307692307692\n",
      "\tStandard deviation of feature nonflavanoid_phenols: 342.6471335484861\n",
      "\tAverage value of feature proanthocyanins: 91.67846153846153\n",
      "\tStandard deviation of feature proanthocyanins: 276.3289785701694\n",
      "\tAverage value of feature color_intensity: 92.03538461538461\n",
      "\tStandard deviation of feature color_intensity: 276.2461894652718\n",
      "\tAverage value of feature hue: 128.5076923076923\n",
      "\tStandard deviation of feature hue: 399.71556487378234\n",
      "\tAverage value of feature od280/od315_of_diluted_wines: 109.62846153846155\n",
      "\tStandard deviation of feature od280/od315_of_diluted_wines: 338.7445817187147\n",
      "\tAverage value of feature proline: 112.3076923076923\n",
      "\tStandard deviation of feature proline: 349.38016136611566\n"
     ]
    }
   ],
   "source": [
    "print(diabetes_data_set.data)\n",
    "# print(iris_data_set.feature_names)\n",
    "from sklearn.utils import Bunch\n",
    "import numpy as np\n",
    "def prepare_dataset_description(data_set : Bunch, data_set_name):\n",
    "    \n",
    "    description = \"Dataset \" + data_set_name + \"\\n\"\n",
    "    description += \"Number of samples \" + str(len(data_set.data))\n",
    "    try: \n",
    "        num_of_classes = len(data_set.target_names)\n",
    "        description += \"\\nNumber of classes \" + str(num_of_classes)\n",
    "\n",
    "        _, counts = np.unique(data_set.target, return_counts=True)\n",
    "        for i, j in enumerate(data_set.target_names):\n",
    "            try:\n",
    "                description += \"\\n\\tNumber of samples in class \" + j + \": \" + str(counts[i])\n",
    "            except:\n",
    "                description += \"\\n\\tNumber of samples in class \" + str(j) + \": \" + str(counts[i])\n",
    "\n",
    "    except:\n",
    "        description += \"\\nNumber of classes 0\" \n",
    "\n",
    "    num_of_features = len(data_set.feature_names)\n",
    "    description += \"\\nNumber of features \" + str(num_of_features)\n",
    "    for i, j in enumerate(data_set.feature_names):\n",
    "        avg = np.mean(data_set.data[i])\n",
    "        std = np.std(data_set.data[i])\n",
    "        description += \"\\n\\tAverage value of feature \" + j + \": \" + str(avg)\n",
    "        description += \"\\n\\tStandard deviation of feature \" + j + \": \" + str(std)\n",
    "\n",
    "\n",
    "    return description\n",
    "    \n",
    "print(prepare_dataset_description(iris_data_set, 'Iris'))\n",
    "print(prepare_dataset_description(breast_cancer_data_set, 'BC'))\n",
    "print(prepare_dataset_description(digits_data_set, 'Digits'))\n",
    "print(prepare_dataset_description(diabetes_data_set, 'Diabetes'))\n",
    "print(prepare_dataset_description(linnerud_data_set, 'Linnerud'))\n",
    "print(prepare_dataset_description(wine_data_set, 'Wine'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0cc2e28e15ec3d399ff2fa987eff54814158b78b1ea93d5ce0744d3e4b658fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
